{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9363b9-8195-4d32-9857-9ccf13a353be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae921c79-cc56-455c-be96-fc9c162c45c3",
   "metadata": {},
   "source": [
    "### LOAD BIO files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5444600b-53c5-4769-9420-02c53c4745f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIO_PATH ='C:/Projects/try1/bio_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e753212d-8eb1-418b-b0e2-022b91c38799",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files =[]\n",
    "for i in os.listdir(BIO_PATH):\n",
    "    f = os.path.join(BIO_PATH,i)\n",
    "    if i.endswith('.bio'):\n",
    "        all_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae783ac-ec66-4009-8485-a1f153f59ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f5f26-3bc3-41c0-b0e9-f7ee6e5a40a8",
   "metadata": {},
   "source": [
    "## Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72fcf3-0a3f-4edb-92ef-61fa97199c2f",
   "metadata": {},
   "source": [
    "### Remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c18303a-3cf8-40dc-bc6b-5df6025cfa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tannn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd6e8b-6886-47d3-a95b-f8f6ea1aafbf",
   "metadata": {},
   "source": [
    "## Separate the data into labels and sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303332a7-7b1e-4eda-8ad0-bac2327d0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "labels =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2e1740-9ebe-4e8e-a8d1-34088df9cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72278778-801f-4f23-bee2-9c3e26d9dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in all_files:\n",
    "    with open(files, 'r',encoding = 'utf-8') as f:\n",
    "        current_sentence = []\n",
    "        current_label =[]\n",
    "        for line in f:\n",
    "            if line.strip() == '':\n",
    "                sentences.append(current_sentence)\n",
    "                labels.append(current_label)\n",
    "\n",
    "                current_sentence =[]\n",
    "                current_label =[]\n",
    "                continue\n",
    "            #print(line)\n",
    "            word = line.strip().split(\"\\t\")[0]\n",
    "            tag = line.strip().split(\"\\t\")[1]\n",
    "\n",
    "            cleaned_word = re.sub(r'[^a-zA-Z]', '', word)\n",
    "        \n",
    "            if cleaned_word in STOPWORDS:\n",
    "                cleaned_word = ' '\n",
    "            else:\n",
    "                doc = nlp(cleaned_word)\n",
    "                lemmatized_word = \" \".join([token.lemma_ for token in doc])\n",
    "                cleaned_word = lemmatized_word\n",
    "\n",
    "            if cleaned_word.strip():\n",
    "\n",
    "                current_sentence.append(cleaned_word)\n",
    "                if len(current_label) > 0:\n",
    "                    if tag[2:] == current_label[-1][2:] and tag[:2] == \"B-\":\n",
    "                        tag = f\"I-{tag[2:]}\"\n",
    "                current_label.append(tag)           \n",
    "     \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a98dfc7-dcbf-4774-b2b6-7221da14b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 4741 examples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset contains {len(sentences)} examples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7680ad98-3f11-4483-a189-f842a8cdaa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 4741 examples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset contains {len(labels)} examples\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d331f7-21c4-4517-9439-eb8b0de1446e",
   "metadata": {},
   "source": [
    "## Prepare training Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9330ab63-37bf-43b0-96e4-6d6337b86efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = list(zip(sentences, labels))\n",
    "random.shuffle(combined_data)\n",
    "sentences, categorical_labels = zip(*combined_data)\n",
    "\n",
    "sentences_train, sentences_temp, labels_train, labels_temp = train_test_split(sentences, categorical_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "sentences_validation, sentences_test, labels_validation, labels_test = train_test_split(sentences_temp, labels_temp, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "max_sequence_length = 200  \n",
    "train_sequences = tokenizer.texts_to_sequences(sentences_train)\n",
    "validation_sequences = tokenizer.texts_to_sequences(sentences_validation)\n",
    "test_sequences = tokenizer.texts_to_sequences(sentences_test)\n",
    "train_padded_sequences = pad_sequences(train_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "validation_padded_sequences = pad_sequences(validation_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "test_padded_sequences = pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e77a53c-d594-4d73-a8e4-b284b35c5aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "flat_labels_train = [label for sublist in labels_train for label in sublist]\n",
    "flat_labels_validation = [label for sublist in labels_validation for label in sublist]\n",
    "flat_labels_test = [label for sublist in labels_test for label in sublist]\n",
    "\n",
    "unique_labels_set = set(flat_labels_train).union(set(flat_labels_test))\n",
    "print(len(unique_labels_set))\n",
    "# Map labels to their one-hot encoded index\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef48aa3b-090b-492c-a336-06360dc92148",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = {id: label for label, id in label_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c8aa07d-66a9-4152-9893-5c3afa2c4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index['<PAD>'] = 0\n",
    "index_to_label[0] = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9aae7a4-d970-48a2-b898-cea6e83b7076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(index_to_label)\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08d253ba-9445-4a25-84dd-bcccaaa66a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 200\n",
    "train_labels = [[label_to_index[label] for label in labels] for labels in labels_train]\n",
    "train_labels = pad_sequences(train_labels, maxlen=MAX_LENGTH, padding='post', value=NUM_CLASSES-1)\n",
    "train_labels = to_categorical(train_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "valid_labels = [[label_to_index[label] for label in labels] for labels in labels_validation]\n",
    "valid_labels = pad_sequences(valid_labels, maxlen=MAX_LENGTH, padding='post', value=NUM_CLASSES-1)\n",
    "valid_labels = to_categorical(valid_labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "test_labels = [[label_to_index[label] for label in labels] for labels in labels_test]\n",
    "test_labels = pad_sequences(test_labels, maxlen=MAX_LENGTH, padding='post', value=NUM_CLASSES-1)\n",
    "test_labels = to_categorical(test_labels, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a94b9df-c644-4893-994c-c7cd81334477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3792, 200, 82)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9ce1500-2357-4d05-bef8-01727238a3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3792, 200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99e98410-0c42-46a2-91ea-55a416b46357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Projects/try1\\\\preprocessed_data_2.npz'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = \"C:/Projects/try1\"  # Replace with your desired directory\n",
    "file_name = \"preprocessed_data_2.npz\"  # Replace with your desired file name\n",
    "file_path = os.path.join(directory, file_name)\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f0cf3f-bc8e-4e44-ade1-03bc4ecf739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(file_path,\n",
    "         train_padded_sequences=train_padded_sequences,\n",
    "         test_padded_sequences=test_padded_sequences,\n",
    "         validation_padded_sequences=validation_padded_sequences,\n",
    "         train_labels=train_labels,\n",
    "         test_labels=test_labels,\n",
    "         valid_labels=valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dfad052-885d-4eae-bf71-b30dca528678",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "EMBEDDING_DIM = 128\n",
    "max_sequence_length = 200\n",
    "num_labels = 82\n",
    "NUM_EPOCHS = 10\n",
    "num_classes = 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d56e0ff-67d4-49c8-901b-a2e05237b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(tokenizer.word_index)+1\n",
    "EMBEDDING_DIM = 64\n",
    "NUM_CLASSES = len(index_to_label)\n",
    "MAX_LENGTH = train_padded_sequences.shape[1]\n",
    "LSTM_UNITS = 64\n",
    "DENSE_UNITS = 64\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfcae285-75c8-44cf-be52-8acf830a5c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5eba8-fc25-449f-a5b3-37b26dfbb632",
   "metadata": {},
   "source": [
    "## Model 1: CNN-BILSTM with word Word2Vec Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93e244e3-1d29-4393-b9ca-6d1553d7f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 64)           442688    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 200, 32)           6176      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 200, 128)          49664     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 200, 64)           8256      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 64)           0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200, 82)           5330      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 512114 (1.95 MB)\n",
      "Trainable params: 512114 (1.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([    \n",
    "    tf.keras.layers.Embedding(input_dim=INPUT_DIM, output_dim=EMBEDDING_DIM, input_length=MAX_LENGTH),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=LSTM_UNITS, return_sequences=True)),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=DENSE_UNITS, activation='relu')),\n",
    "    tf.keras.layers.Dropout(rate=DROPOUT_RATE),\n",
    "    tf.keras.layers.Dense(units=NUM_CLASSES, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9dc6007-2b42-45b2-8f76-4937c1528f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "119/119 [==============================] - 16s 94ms/step - loss: 0.7015 - accuracy: 0.9444 - val_loss: 0.1651 - val_accuracy: 0.9643\n",
      "Epoch 2/20\n",
      "119/119 [==============================] - 10s 84ms/step - loss: 0.1616 - accuracy: 0.9655 - val_loss: 0.1610 - val_accuracy: 0.9661\n",
      "Epoch 3/20\n",
      "119/119 [==============================] - 10s 86ms/step - loss: 0.1523 - accuracy: 0.9673 - val_loss: 0.1654 - val_accuracy: 0.9664\n",
      "Epoch 4/20\n",
      "119/119 [==============================] - 10s 85ms/step - loss: 0.1498 - accuracy: 0.9676 - val_loss: 0.1712 - val_accuracy: 0.9664\n",
      "Epoch 5/20\n",
      "119/119 [==============================] - 10s 84ms/step - loss: 0.1489 - accuracy: 0.9676 - val_loss: 0.1748 - val_accuracy: 0.9664\n",
      "Epoch 6/20\n",
      "119/119 [==============================] - 10s 85ms/step - loss: 0.1475 - accuracy: 0.9676 - val_loss: 0.1788 - val_accuracy: 0.9662\n",
      "Epoch 7/20\n",
      "119/119 [==============================] - 10s 84ms/step - loss: 0.1454 - accuracy: 0.9676 - val_loss: 0.1796 - val_accuracy: 0.9663\n",
      "Epoch 8/20\n",
      "119/119 [==============================] - 10s 84ms/step - loss: 0.1406 - accuracy: 0.9678 - val_loss: 0.1827 - val_accuracy: 0.9661\n",
      "Epoch 9/20\n",
      "119/119 [==============================] - 10s 84ms/step - loss: 0.1359 - accuracy: 0.9681 - val_loss: 0.1865 - val_accuracy: 0.9663\n",
      "Epoch 10/20\n",
      "119/119 [==============================] - 10s 84ms/step - loss: 0.1305 - accuracy: 0.9683 - val_loss: 0.1926 - val_accuracy: 0.9661\n",
      "Epoch 11/20\n",
      "119/119 [==============================] - 10s 83ms/step - loss: 0.1257 - accuracy: 0.9687 - val_loss: 0.2031 - val_accuracy: 0.9655\n",
      "Epoch 12/20\n",
      "119/119 [==============================] - 10s 83ms/step - loss: 0.1217 - accuracy: 0.9691 - val_loss: 0.2092 - val_accuracy: 0.9657\n",
      "Epoch 13/20\n",
      "119/119 [==============================] - 10s 84ms/step - loss: 0.1175 - accuracy: 0.9696 - val_loss: 0.2184 - val_accuracy: 0.9649\n",
      "Epoch 14/20\n",
      "119/119 [==============================] - 10s 84ms/step - loss: 0.1131 - accuracy: 0.9703 - val_loss: 0.2253 - val_accuracy: 0.9647\n",
      "Epoch 15/20\n",
      "119/119 [==============================] - 10s 85ms/step - loss: 0.1089 - accuracy: 0.9711 - val_loss: 0.2354 - val_accuracy: 0.9633\n",
      "Epoch 16/20\n",
      "119/119 [==============================] - 11s 93ms/step - loss: 0.1050 - accuracy: 0.9718 - val_loss: 0.2455 - val_accuracy: 0.9627\n",
      "Epoch 17/20\n",
      "119/119 [==============================] - 16s 136ms/step - loss: 0.1008 - accuracy: 0.9725 - val_loss: 0.2526 - val_accuracy: 0.9616\n",
      "Epoch 18/20\n",
      "119/119 [==============================] - 16s 137ms/step - loss: 0.0970 - accuracy: 0.9733 - val_loss: 0.2615 - val_accuracy: 0.9618\n",
      "Epoch 19/20\n",
      "119/119 [==============================] - 16s 137ms/step - loss: 0.0933 - accuracy: 0.9741 - val_loss: 0.2749 - val_accuracy: 0.9613\n",
      "Epoch 20/20\n",
      "119/119 [==============================] - 16s 137ms/step - loss: 0.0895 - accuracy: 0.9750 - val_loss: 0.2864 - val_accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_padded_sequences, \n",
    "    train_labels, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=(validation_padded_sequences, valid_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2cc3cc4-1989-4889-b25e-90d4372527f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 47ms/step - loss: 0.3024 - accuracy: 0.9594\n",
      "Test loss: 0.3024, Test accuracy: 0.9594\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)\n",
    "print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07be0458-8935-406c-9c7b-4e43b5eec8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77b60c-987d-4ada-8adb-6d1a5ce898b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64dba210-3720-4da8-bc7f-a4d3c80f0d58",
   "metadata": {},
   "source": [
    "## Model 2: BiLSTM with BioVector  Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9b86c37-27ad-4c0e-9adb-d71a0266f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49c2c6-9c9b-4143-8e9b-c66c4d6bb57b",
   "metadata": {},
   "source": [
    "### Load BioVector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42b21a16-ce8c-4c16-abe4-f8e0bc81ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_file = \"C:\\Projects\\try1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4656613a-c8a2-414b-b9fa-a12481b7dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_vectors = r'C:\\Projects\\try1\\BioWordVec_PubMed_MIMICIII_d200.vec.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90d60310-e795-4295-b82f-544f49fde34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "biowv = gensim.models.KeyedVectors.load_word2vec_format(path_to_vectors, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "573b1497-c602-4668-860b-50d3d5664f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1fd3ed78bd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biowv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f61abf-7676-470a-847a-27054295d8b7",
   "metadata": {},
   "source": [
    "### Create  BioVector Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48244c98-7380-48cc-8169-e145428b8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200  \n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in biowv:\n",
    "        embedding_matrix[i] = biowv[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1d3ce23-b2e5-4a50-a0e2-022c02aedc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=len(tokenizer.word_index) + 1,\n",
    "    output_dim=embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=max_sequence_length,\n",
    "    trainable=False \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "387f1bf8-da9b-4ccf-b6f7-ebe4684d7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioVectorEmbeddingLayer(Layer):\n",
    "    def __init__(self, biowv, input_dim, output_dim, trainable=False, **kwargs):\n",
    "        super(BioVectorEmbeddingLayer, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.trainable = trainable\n",
    "        self.embeddings = Embedding(input_dim=input_dim, output_dim=output_dim, trainable=trainable,\n",
    "                                   embeddings_initializer=self.get_initializer(biowv))\n",
    "\n",
    "    def get_initializer(self, biowv):\n",
    "        embedding_matrix = np.zeros((self.input_dim, self.output_dim))\n",
    "        for word, i in biowv.index2word:\n",
    "            if i < self.input_dim:\n",
    "                embedding_matrix[i] = biowv[word]\n",
    "        return tf.constant_initializer(embedding_matrix)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.embeddings(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fee0a2-c5a4-4d55-b457-aaf47e59098b",
   "metadata": {},
   "source": [
    "### Model Archtecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8128ed86-4c76-459f-b7a2-5c1275c8c4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 200, 200)          1383400   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 200, 128)          135680    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 200, 64)           8256      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200, 64)           0         \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDi  (None, 200, 82)           5330      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1532666 (5.85 MB)\n",
      "Trainable params: 149266 (583.07 KB)\n",
      "Non-trainable params: 1383400 (5.28 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    embedding_layer,    \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=LSTM_UNITS, return_sequences=True)),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=DENSE_UNITS, activation='relu')),\n",
    "    tf.keras.layers.Dropout(rate=DROPOUT_RATE),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=NUM_CLASSES, activation='softmax'))\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd6bdc3d-3869-45fa-966f-80b9add08679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "119/119 [==============================] - 36s 211ms/step - loss: 0.7274 - accuracy: 0.9556 - val_loss: 0.1671 - val_accuracy: 0.9664\n",
      "Epoch 2/20\n",
      "119/119 [==============================] - 21s 175ms/step - loss: 0.1520 - accuracy: 0.9675 - val_loss: 0.1691 - val_accuracy: 0.9664\n",
      "Epoch 3/20\n",
      "119/119 [==============================] - 20s 172ms/step - loss: 0.1497 - accuracy: 0.9676 - val_loss: 0.1710 - val_accuracy: 0.9664\n",
      "Epoch 4/20\n",
      "119/119 [==============================] - 21s 173ms/step - loss: 0.1478 - accuracy: 0.9676 - val_loss: 0.1692 - val_accuracy: 0.9665\n",
      "Epoch 5/20\n",
      "119/119 [==============================] - 21s 175ms/step - loss: 0.1454 - accuracy: 0.9678 - val_loss: 0.1680 - val_accuracy: 0.9667\n",
      "Epoch 6/20\n",
      "119/119 [==============================] - 21s 174ms/step - loss: 0.1437 - accuracy: 0.9678 - val_loss: 0.1664 - val_accuracy: 0.9667\n",
      "Epoch 7/20\n",
      "119/119 [==============================] - 20s 168ms/step - loss: 0.1422 - accuracy: 0.9679 - val_loss: 0.1653 - val_accuracy: 0.9667\n",
      "Epoch 8/20\n",
      "119/119 [==============================] - 20s 168ms/step - loss: 0.1410 - accuracy: 0.9679 - val_loss: 0.1685 - val_accuracy: 0.9667\n",
      "Epoch 9/20\n",
      "119/119 [==============================] - 20s 168ms/step - loss: 0.1400 - accuracy: 0.9679 - val_loss: 0.1677 - val_accuracy: 0.9667\n",
      "Epoch 10/20\n",
      "119/119 [==============================] - 20s 168ms/step - loss: 0.1390 - accuracy: 0.9679 - val_loss: 0.1672 - val_accuracy: 0.9667\n",
      "Epoch 11/20\n",
      "119/119 [==============================] - 21s 175ms/step - loss: 0.1382 - accuracy: 0.9680 - val_loss: 0.1640 - val_accuracy: 0.9669\n",
      "Epoch 12/20\n",
      "119/119 [==============================] - 21s 173ms/step - loss: 0.1373 - accuracy: 0.9680 - val_loss: 0.1681 - val_accuracy: 0.9669\n",
      "Epoch 13/20\n",
      "119/119 [==============================] - 21s 174ms/step - loss: 0.1363 - accuracy: 0.9680 - val_loss: 0.1648 - val_accuracy: 0.9668\n",
      "Epoch 14/20\n",
      "119/119 [==============================] - 20s 172ms/step - loss: 0.1355 - accuracy: 0.9681 - val_loss: 0.1652 - val_accuracy: 0.9669\n",
      "Epoch 15/20\n",
      "119/119 [==============================] - 21s 173ms/step - loss: 0.1347 - accuracy: 0.9681 - val_loss: 0.1703 - val_accuracy: 0.9670\n",
      "Epoch 16/20\n",
      "119/119 [==============================] - 21s 174ms/step - loss: 0.1338 - accuracy: 0.9681 - val_loss: 0.1723 - val_accuracy: 0.9671\n",
      "Epoch 17/20\n",
      "119/119 [==============================] - 21s 174ms/step - loss: 0.1327 - accuracy: 0.9682 - val_loss: 0.1722 - val_accuracy: 0.9670\n",
      "Epoch 18/20\n",
      "119/119 [==============================] - 21s 174ms/step - loss: 0.1318 - accuracy: 0.9683 - val_loss: 0.1653 - val_accuracy: 0.9669\n",
      "Epoch 19/20\n",
      "119/119 [==============================] - 21s 174ms/step - loss: 0.1306 - accuracy: 0.9683 - val_loss: 0.1735 - val_accuracy: 0.9670\n",
      "Epoch 20/20\n",
      "119/119 [==============================] - 21s 172ms/step - loss: 0.1297 - accuracy: 0.9684 - val_loss: 0.1662 - val_accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_padded_sequences, \n",
    "    train_labels, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=(validation_padded_sequences, valid_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17703376-c236-49c7-a014-655747371df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 84ms/step - loss: 0.1758 - accuracy: 0.9643\n",
      "Test loss: 0.1758, Test accuracy: 0.9643\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)\n",
    "print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e5d39-4fcc-41ba-b00c-e1e75009cb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574f918-0872-4c92-974d-f72d28750d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98cecb-651b-43f0-9b59-e96bc9ceac30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
